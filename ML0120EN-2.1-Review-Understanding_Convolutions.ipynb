{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=\"center\"><font size=\"5\">UNDERSTANDING CONVOLUTIONS</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lesson</h3>\n",
    "In this lesson, we will learn more about the key concepts behind the CNNs (Convolutional Neural Networks from now on).\n",
    "This lesson is not intended to be a reference for <b>machine learning, deep learning, convolutions</b> or <b>TensorFlow</b>. The intention is to give notions to the user about these fields. \n",
    "\n",
    "<h3>Audience</h3>\n",
    "<ul>\n",
    "    <li>Data scientists. General public related to computer science and machine learning.</li>\n",
    "    <li>Readers interested on TensorFlow and in need of a cloud platform like Workbench Data Scientist.</li>\n",
    "</ul>\n",
    "        \n",
    "<h3>Pre-requisites:</h3>\n",
    "Basic knowledge of linear algebra, Python, Neural Networks and TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of contents</h2>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size=\"3\"><strong>Click on the links to go to the following sections:</strong></font>\n",
    "<br>\n",
    "<ol>\n",
    "    <li><a href=\"#ref1\">Analogies</a></li>\n",
    "    <li><a href=\"#ref2\">Understanding and coding with Python</a></li>\n",
    "    <li><a href=\"#ref3\">Coding with TensorFlow</a></li>\n",
    "    <li><a href=\"#ref4\">Convolution applied on images</a></li>\n",
    "    <li><a href=\"#ref5\">Conclusion</a></li>\n",
    "</ol>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h2>Analogies</h2>\n",
    "\n",
    "There are several ways to understand Convolutional Layers without using a mathematical approach. We are going to explore some of the ideas proposed by the Machine Learning community.\n",
    "\n",
    "<h3>Instances of Neurons</h3>\n",
    "\n",
    "When you start to learn a programming language, one of the first phases of your development is the learning and application of functions. Instead of rewriting pieces of code everytime that you would, a good student is encouraged to code using functional programming, keeping the code organized, clear and concise.\n",
    "CNNs can be thought of as a simplification of what is really going on, a special kind of neural network which uses identical copies of the same neuron. These copies include the same parameters (shared weights and biases) and activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Location and type of connections</h3>\n",
    "\n",
    "In a fully connected layer NN, each neuron in the current layer is connected to every neuron in the previous layer, and each connection has it's own weight. This is a general purpose connection pattern and makes no assumptions about the features in the input data thus not taking any advantage that the knowledge of the data being used can bring. These types of layers are also very expensive in terms of memory and computation.\n",
    "\n",
    "In contrast, in a convolutional layer each neuron is only connected to a few nearby local neurons in the previous layer, and the same set of weights is used to connect to them. For example, in the following image, the neurons in the h1 layer are connected only to some input units (pixels).\n",
    "      \n",
    "<img src=\"https://ibm.box.com/shared/static/mev168hepixnmc9zhh4hsr3t2ks3rpcc.png\" alt=\"HTML5 Icon\" style=\"width: 500px; height: 500px;\">\n",
    "<center> A figure presented in one of Yann LeCun's papers. It shows the spatial relation and how the connections are modified until the output layer <a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf\">ref</a></center> \n",
    "\n",
    "\n",
    "      \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Learning</h2>\n",
    "\n",
    "Feature engineering is the process of extracting useful patterns from input data that will help the prediction model to understand better the real nature of the problem. A good feature learning will present patterns in a way that significantly increase the accuracy and performance of the applied machine learning algorithms in a way that would otherwise be impossible or too expensive by just machine learning itself.\n",
    "\n",
    "Feature learning algorithms finds the common patterns that are important to distinguish between the wanted classes and extract them automatically. After this process, they are ready to be used in a classification or regression problem. \n",
    "\n",
    "The great advantage of CNNs is that they are uncommonly good at finding features in images that grow after each level, resulting in high-level features in the end. The final layers (can be one or more) use all these generated features for classification or regression. \n",
    "\n",
    "Basically, Convolutional Neural Networks is your best friend to <b>automatically do Feature Engineering</b> (Feature Learning) without wasting too much time creating your own codes and with no prior need of expertise in the field of Feature Engineering.\n",
    "<br>\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/urzzkc7o5loqrlezcvn4kr594mxi9ftx.png\" alt=\"HTML5 Icon\" style=\"width: 650px; height: 250px;\">\n",
    "<center> \n",
    "    Example of feature learning (automatically feature engineering), starting with simple features and ending with high-level features like human faces. <a href=\"https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/\">ref</a> \n",
    "</center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image Filter</h3>\n",
    "\n",
    "<b>How to create a convolved freature from an image ?</b>  \n",
    "The image below is a 8x8 matrix of an image's pixels, converted to binary values in the next image(left), where 1 means a white pixel and 0 a black pixel. Later we will find out that typically this is a normalization, these values can actually have different scales. The most common usage is values between 0 and 255 for 8-bit grayscale images.  \n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/0s5v7doe2p5xuzifs47bxmmuwrn3kra2.bmp\" alt=\"HTML5 Icon\" style=\"width: 200px; height: 200px;\">\n",
    "<center> An example of a low resolution image to be recognized.\n",
    "\n",
    "In the below image, with an animation, you can see how the two-dimensional convolution operation would operate on the images. This operation is performed in most of the Deep Learning frameworks in their first phase. We need a sliding windows to create the convolved matrix:\n",
    "\n",
    "$\n",
    "kernel=\n",
    "\\begin{bmatrix}\n",
    "     1          & 0      & 1     \\\\\n",
    "     0          & 1    & 0     \\\\\n",
    "     1          & 0    & 1\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The sliding window (a.k.a kernel, filter or feature detector) with a preset calculation ([[x1, x0,x1], [x0,x1,x0], [x1,x0,x1]]) goes through the image and creates a new matrix (feature map)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"https://ibm.box.com/shared/static/fvutcm8jwa5j2o7xv2zzqyz2yu3zwhz4.gif\" alt=\"HTML5 Icon\" style=\"width: 450px; height: 300px;\">\n",
    "<center>  Animations showing how a kernel interact with a matrix representing an image. <a href=\"http://cs231n.github.io/convolutional-networks/\">ref</a></center>  \n",
    " \n",
    " \n",
    "In the example above we used a 3Ã—3 filter (5x5 could also be used, but would be too complex). The values from the filter were multiplied element-wise with the original matrix (input image), then summed up. To get the full convolved matrix, the algorithm keep repeating this small procedure for each element by sliding the filter over the whole original matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/7maczejdeej0qoz3pzkysw0y8qb70g2h.png\" alt=\"HTML5 Icon\" style=\"width: 500px; height: 200px;\"> \n",
    "<center>  Illustration of the operation for one position of the kernel. <a href=\"http://colah.github.io/posts/2014-07-Understanding-Convolutions/\">ref</a></center>\n",
    "\n",
    "Just like the referenced example, we can think of a one-dimensional convolution as sliding function (1x1 or 1x2 filter) multiplying and adding on top of an array (1 dimensional array, instead of the original matrix).  \n",
    " \n",
    "<b>What is the output of applying a kernel on an image?</b>   \n",
    "The famous GIMP (Open Source Image Editor) has an explanation about the convolution operation applied to images that can help us understand how Neural Networks will interact with this tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/wixvbo9pk0f6r6ln879ah9jjo0ua0fo5.png\" alt=\"HTML5 Icon\" style=\"width: 700px; height: 350px;\"> \n",
    "<center>   Applying the left kernel to the image will result into a blur effect. <a href=\"http://colah.github.io/posts/2014-07-Understanding-Convolutions/\">ref</a> </center>\n",
    "\n",
    "\n",
    "Well, this is very good if you want nice effects for your social media photos, but in the field of computer vision you need detailed patterns (remember feature learning) that are almost erased using a kernel like that. A more suitable example would be the Kernel/filter that shows edges from photos (the first recognizable feature of an image).\n",
    "\n",
    "\n",
    "<b>Lets try another kernel:</b>  \n",
    "Taking the values âˆ’1 and 1 on two adjacent pixels and zero everywhere else for the kernel, results in the following image. That is, we subtract two adjacent pixels. When side by side pixels are similar, this gives us approximately zero. On edges, however, adjacent pixels are very different in the direction perpendicular to the edge. Knowing that results differs from zero will result in brighter pixels, you can already guess the result of this type of kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/z673yijcsfqs5rd8auc1dwmtkejyizv0.png\" alt=\"HTML5 Icon\" style=\"width:700px;height:350px;\">\n",
    "<center> Applying the new left kernel to the image will result into a edge detection, this output is normally useful for the initial layers of a CNN. <a href=\"http://colah.github.io/posts/2014-07-Understanding-Convolutions/\">ref</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "<h2>Understanding and coding with Python</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convolution: 1D operation with Python (Numpy/Scipy)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Mathematical notation</h4>\n",
    "In this first example, we will use the pure mathematical notation. Here we have a one dimensional convolution operation. Lets say h is our image and x is our kernel: \n",
    "  \n",
    "x[i] = { 3, 4, 5 }  \n",
    "h[i] = { 2, 1, 0 }  \n",
    "\n",
    "where i = index\n",
    "\n",
    "To use the convolution operation between the two arrays try the code below to see how easy it is to do in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 11, 14,  5,  0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "h = [2, 1, 0]\n",
    "x = [3, 4, 5]\n",
    " \n",
    "\n",
    "y = np.convolve(x, h)\n",
    "y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sliding x window over h:\n",
    "<ul>\n",
    "    <li>6  = 2 * 3 :            \n",
    "        $\n",
    "        \\begin{bmatrix}\n",
    "             3 & 4 & 5 \\\\\n",
    "        \\end{bmatrix}\n",
    "        \\\\ \n",
    "        \\begin{bmatrix}\n",
    "             2 & 0 & 0 \\\\\n",
    "        \\end{bmatrix}\n",
    "        $ \n",
    "    </li>\n",
    "    <li>11 = 1 * 3 + 2 * 4 :\n",
    "        $\n",
    "        \\begin{bmatrix}\n",
    "             3 & 4 & 5 \\\\\n",
    "        \\end{bmatrix}\n",
    "        \\\\\n",
    "        \\begin{bmatrix}\n",
    "             1 & 2 & 0 \\\\\n",
    "        \\end{bmatrix}\n",
    "        $ \n",
    "    </li>  \n",
    "    <li>14 = 0 * 3 + 1 * 4 + 2 * 5 :\n",
    "        $\n",
    "        \\begin{bmatrix}\n",
    "             3 & 4 & 5 \\\\\n",
    "        \\end{bmatrix}\n",
    "        \\\\\n",
    "        \\begin{bmatrix}\n",
    "             0 & 1 & 2 \\\\\n",
    "        \\end{bmatrix}\n",
    "        $ \n",
    "    </li>  \n",
    "    <li>5  = 0 * 4 + 1 * 5 :\n",
    "        $\n",
    "        \\begin{bmatrix}\n",
    "             3 & 4 & 5 \\\\\n",
    "        \\end{bmatrix}\n",
    "        \\\\\n",
    "        \\begin{bmatrix}\n",
    "             0 & 0 & 1 \\\\\n",
    "        \\end{bmatrix}\n",
    "        $ \n",
    "    </li>\n",
    "    <li>0  = 0 * 5 :\n",
    "        $\n",
    "        \\begin{bmatrix}\n",
    "             3 & 4 & 5 \\\\\n",
    "        \\end{bmatrix}\n",
    "        \\\\\n",
    "        \\begin{bmatrix}\n",
    "             0 & 0 & 0 \\\\\n",
    "        \\end{bmatrix}\n",
    "        $ \n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Now we are going to verify what Python did, because we don't trust computer outputs while we are learning. Using the equation of convolution for y[n]:</h4>\n",
    "  \n",
    "$$y[n] = \\sum\\limits_{k\\to-\\infty}^\\infty x[k] \\cdot h[n-k] $$\n",
    "\n",
    "\n",
    "And then, manually executing computation:\n",
    "\n",
    "$ \n",
    "y[0]= \\sum\\limits_{k\\to-\\infty}^\\infty x[k]\\cdot h[0-k]= x[0]\\cdot h[0]=3\\cdot 2=6 \\\\\n",
    "y[1]= \\sum\\limits_{k\\to-\\infty}^\\infty x[k]\\cdot h[1-k]= x[0]\\cdot h[1-0]+x[1]\\cdot h[1-1] + \\space... \\\\ \n",
    "\\qquad\\qquad\\qquad\\qquad\\qquad   = x[0]\\cdot h[1] + x[1]\\cdot h[0]= 3\\cdot1+4\\cdot 2=11 \\\\\n",
    "y[2]= \\sum\\limits_{k\\to-\\infty}^\\infty x[k]\\cdot h[2-k]= x[0]\\cdot h[2-0]+x[1]\\cdot h[2-1]+x[2]\\cdot h[2-2]+ \\space ... \\\\ \n",
    "\\qquad\\qquad\\qquad\\qquad\\qquad   = x[0]\\cdot h[2] + x[1]\\cdot h[1]+x[2]\\cdot h[0]= 3\\cdot0+4\\cdot 1 +5\\cdot 2=14 \\\\\n",
    "y[3]= \\sum\\limits_{k\\to-\\infty}^\\infty x[k]\\cdot h[3-k]= x[0]\\cdot h[3-0]+x[1]\\cdot h[3-1]+x[2]\\cdot h[3-2]+ x[3]\\cdot h[3-3] + \\space... \\\\ \n",
    "\\qquad\\qquad\\qquad\\qquad\\qquad   = x[0]\\cdot h[3] +x[1]\\cdot h[2] + x[2]\\cdot h[1]+x[3]\\cdot h[0]=0+0+5 \\cdot 1 +0=5 \\\\\n",
    "y[4]= \\sum\\limits_{k\\to-\\infty}^\\infty x[k]\\cdot h[4-k]= x[0]\\cdot h[4-0]+x[1]\\cdot h[4-1]+x[2]\\cdot h[4-2]+\\space... =0\\\\ \n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare with the following values from Python: y[0] = 6 ; y[1] = 11; y[2] = 14; y[3] = 5; y[4] = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Compare with the following values from Python: y[0] = {0} ; y[1] = {1}; y[2] = {2}; y[3] = {3}; y[4] = {4}\".format(y[0], y[1], y[2], y[3], y[4])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three methods to apply kernel on the matrix, <b>with padding (full)</b>, <b>with padding(same)</b> and <b>without padding(valid)</b>:  \n",
    "\n",
    "</h3>1) Visually understanding the operation with padding (full)</h3>\n",
    "\n",
    "Lets think of the kernel as a sliding window. We have to come with the solution of padding zeros on the input array. This is a very famous implementation and will be easier to show how it works with a simple example, consider this case:\n",
    "  \n",
    "x[i] = [6,2]  \n",
    "h[i] = [1,2,5,4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the zero padding, we can calculate the convolution.\n",
    " \n",
    "You have to invert the filter x, otherwise the operation would be cross-correlation.\n",
    "First step, (now with zero padding): "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[2  6]\n",
    " |  |\n",
    " V  V\n",
    " 0 [1 2 5 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 0 + 6 * 1 = 6 \n",
    " \n",
    "Second step:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  [2  6]  \n",
    "   |  |  \n",
    "   V  V  \n",
    "0 [1  2  5  4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 1 + 6 * 2 = 14 (the arrows represent the connection between the kernel and the input)\n",
    "\n",
    "Third step:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "     [2  6]  \n",
    "      |  |  \n",
    "      V  V  \n",
    "0 [1  2  5  4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 2 + 6 * 5 = 34  \n",
    "  \n",
    "Fourth step:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        [2  6]\n",
    "         |  |\n",
    "         V  V\n",
    "0 [1  2  5  4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 5 + 6 * 4 = 34\n",
    "\n",
    "Fifth step:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "           [2  6]\n",
    "            |  |\n",
    "            V  V\n",
    "0 [1  2  5  4] 0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 4 + 6 * 0 = 8\n",
    " \n",
    "The result of the convolution for this case, listing all the steps, would then be: Y = [6 14 34 34 8]\n",
    "\n",
    "Below we verify with numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 14, 34, 34,  8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [6, 2]\n",
    "h = [1, 2, 5, 4]\n",
    "\n",
    "y = np.convolve(x, h, \"full\")  #now, because of the zero padding, the final dimension of the array is bigger\n",
    "y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2) Visually understanding the operation with \"same\"</h3>\n",
    "In this approach, we just add the zero to left (and top of the matrix in 2D). That is, only the first 4 steps of \"full\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 14, 34, 34])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [6, 2]\n",
    "h = [1, 2, 5, 4]\n",
    "\n",
    "y = np.convolve(x, h, \"same\")  # it is same as zero padding, but with returns an ouput with the same length as max of x or h\n",
    "y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3) Visually understanding the operation with no padding (valid)</h3>\n",
    "\n",
    "In the last case we only applied the kernel when we had a compatible position on the h array, in some cases you want a dimensionality reduction. For this purpose, we simple ignore the steps that would need padding:\n",
    "    \n",
    "x[i] = [6 2] \n",
    "\n",
    "h[i] = [1 2 5 4]\n",
    "\n",
    "You have to invert the filter x, otherwise the operation would be cross-correlation.\n",
    "First step, (now without zero padding):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[2  6]  \n",
    " |  |  \n",
    " V  V  \n",
    "[1  2  5  4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 1 + 6 * 2 = 14 (the arrows represent the connection between the kernel and the input)\n",
    "\n",
    "Second step: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "   [2  6]  \n",
    "    |  |   \n",
    "    V  V  \n",
    "[1  2  5  4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 2 + 6 * 5 = 34  \n",
    "  \n",
    "Third step:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "      [2  6]\n",
    "       |  |\n",
    "       V  V\n",
    "[1  2  5  4]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 2 \\* 5 + 6 * 4 = 34\n",
    "\n",
    "The result of the convolution for this mode would then be Y= [14 34 34] = [ First, second, third step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 34, 34])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [6, 2]\n",
    "h = [1, 2, 5, 4]\n",
    "\n",
    "y = np.convolve(x, h, \"valid\")   # valid returns output of length max(x, h) - min(x, h) + 1, this is to ensure that values outside of the boundary of \n",
    "                                # h will not be used in the calculation of the convolution\n",
    "                                # in the next example we will understand why we used the argument valid\n",
    "y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convolution: 2D operation with Python (Numpy/Scipy)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D convolution operation is defined as:\n",
    "\n",
    "<font size=\"4\">$$ I'= \\sum\\limits_{u,v} I(x-u,y-v)g(u,v) $$ </font> \n",
    " \n",
    " \n",
    "Below we will apply the equation to an image represented by a 3x3 matrix according to the function g = (-1 1). <u>Please note that when we apply the kernel we always use its inversion.</u> \n",
    " \n",
    "$\n",
    "I=\n",
    "\\begin{bmatrix}\n",
    "     255          & 7      & 3     \\\\\n",
    "     212          & 240    & 4     \\\\\n",
    "     218          & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$ \n",
    "\n",
    "$\n",
    "g=\n",
    "\\begin{bmatrix}\n",
    "     -1          & 1      \n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$ \n",
    "  \n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    \\textbf{1}\\cdot \\textbf{0}      & \\textbf{-1} \\ast \\textbf{255}  & 7      & 3     \\\\\n",
    "    0              & 212          & 240    & 4     \\\\\n",
    "    0              & 218          & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    \\textbf{-255}  & 7      & 3     \\\\\n",
    "    212            & 240    & 4     \\\\\n",
    "    218            & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    \\textbf{1}\\ast \\textbf{255}      & \\textbf{-1} \\ast \\textbf{7}  & 3    \\\\\n",
    "    212          & 240    & 4     \\\\\n",
    "    218          & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    -255           & \\textbf{248}      & 3     \\\\\n",
    "    212            & 240    & 4     \\\\\n",
    "    218            & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    255          & \\textbf{1}\\ast\\textbf{7}  & \\textbf{-1}\\ast\\textbf{3}    \\\\\n",
    "    212          & 240    & 4     \\\\\n",
    "    218          & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    -255           & 248      & \\textbf{4}     \\\\\n",
    "    212            & 240      & 4     \\\\\n",
    "    218            & 216      & 230\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$\n",
    "\n",
    "  \n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    0              & 255          & 7          & 3     \\\\\n",
    "    \\textbf{1}\\ast \\textbf{0}    & \\textbf{-1} \\ast \\textbf{212}  & 240     & 4     \\\\\n",
    "    0              & 218          & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    \\textbf{-255}  & 248    & 4     \\\\\n",
    "    -212            & 240    & 4     \\\\\n",
    "    218            & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to finish the calculations, we have the computer at our side. So, let's see what is the code to proceede with this operation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without zero padding \n",
      "\n",
      "[[248   4]\n",
      " [-28 236]\n",
      " [  2 -14]] \n",
      "\n",
      "With zero padding \n",
      "\n",
      "[[-255  248    4    3]\n",
      " [-212  -28  236    4]\n",
      " [-218    2  -14  230]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal as sg\n",
    "\n",
    "I= [[255,   7,  3],\n",
    "    [212, 240,  4],\n",
    "    [218, 216, 230],]\n",
    "\n",
    "g= [[-1, 1]]\n",
    "\n",
    "print('Without zero padding \\n')\n",
    "print('{0} \\n'.format(sg.convolve( I, g, 'valid')))\n",
    "# The 'valid' argument states that the output consists only of those elements \n",
    "# that do not rely on the zero-padding.\n",
    "\n",
    "print('With zero padding \\n')\n",
    "print(sg.convolve( I, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** `np.convolve` only works for 1-D arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more difficult case where h= [ [-1  1] , [2   3] ]\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    \\textbf{3}\\ast \\textbf{0}      & \\textbf{2} \\ast \\textbf{0}     & 0      & 0     \\\\\n",
    "    \\textbf{1}\\ast \\textbf{0}      & \\textbf{-1} \\ast \\textbf{255}  & 7      & 3     \\\\\n",
    "    0              & 212          & 240    & 4     \\\\\n",
    "    0              & 218          & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    \\textbf{-255}  & 7      & 3     \\\\\n",
    "    212            & 240    & 4     \\\\\n",
    "    218            & 216    & 230\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With zero padding \n",
      "\n",
      "[[-255  248    4    3]\n",
      " [ 298  751  263   13]\n",
      " [ 206 1118  714  242]\n",
      " [ 436 1086 1108  690]] \n",
      "\n",
      "With zero padding_same_ \n",
      "\n",
      "[[-255  248    4]\n",
      " [ 298  751  263]\n",
      " [ 206 1118  714]] \n",
      "\n",
      "Without zero padding \n",
      "\n",
      "[[ 751  263]\n",
      " [1118  714]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal as sg\n",
    "\n",
    "I= [[255,   7,  3],\n",
    "    [212, 240,  4],\n",
    "    [218, 216, 230],]\n",
    "\n",
    "g= [[-1,  1],\n",
    "    [ 2,  3],]\n",
    "\n",
    "print ('With zero padding \\n')\n",
    "print ('{0} \\n'.format(sg.convolve( I, g, 'full')))\n",
    "# The output is the full discrete linear convolution of the inputs. \n",
    "# It will use zero to complete the input matrix\n",
    "\n",
    "print ('With zero padding_same_ \\n')\n",
    "print ('{0} \\n'.format(sg.convolve( I, g, 'same')))\n",
    "# The output is the full discrete linear convolution of the inputs. \n",
    "# It will use zero to complete the input matrix\n",
    "\n",
    "\n",
    "print ('Without zero padding \\n')\n",
    "print (sg.convolve( I, g, 'valid'))\n",
    "# The 'valid' argument states that the output consists only of those elements \n",
    "#that do not rely on the zero-padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref3\"></a>\n",
    "<h2>Coding with TensorFlow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is great because it has high optimized matrix operations implemented in a backend using C/C++. However, if our goal is to work with DeepLearning, we need much more. TensorFlow does the same work, but instead of returning to Python everytime, it creates all the operations in the form of graphs and execute them once with the highly optimized backend.\n",
    "\n",
    "Suppose that you have two tensors:\n",
    "\n",
    "* 3x3 filter (4D tensor = [3,3,1,1] = [width, height, channels, number of filters])\n",
    "* 10x10 image (4D tensor = [1,10,10,1] = [batch size, width, height, number of channels]\n",
    "\n",
    "The output size for zero padding 'SAME' mode will be:  \n",
    "* the same as input = 10x10  \n",
    "\n",
    "The output size without zero padding 'VALID' mode:  \n",
    "* input size - kernel dimension + 1 = 10 -3 + 1 = 8 = 8x8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input \n",
      "\n",
      "[[[[ 2.1909912 ]\n",
      "   [ 0.55619615]\n",
      "   [ 0.4303969 ]\n",
      "   [-0.7046688 ]\n",
      "   [ 0.27803653]\n",
      "   [-0.005943  ]\n",
      "   [-0.8210736 ]\n",
      "   [-0.05259315]\n",
      "   [-0.391784  ]\n",
      "   [ 1.6819103 ]]\n",
      "\n",
      "  [[ 1.2125412 ]\n",
      "   [ 0.8502383 ]\n",
      "   [-0.94135   ]\n",
      "   [ 1.1262658 ]\n",
      "   [ 1.0453994 ]\n",
      "   [ 0.16770895]\n",
      "   [ 0.47222126]\n",
      "   [-0.590806  ]\n",
      "   [-0.34882304]\n",
      "   [ 0.7009895 ]]\n",
      "\n",
      "  [[-0.04520366]\n",
      "   [-1.1762849 ]\n",
      "   [ 0.08280034]\n",
      "   [-0.15454943]\n",
      "   [ 0.22785468]\n",
      "   [ 0.00718881]\n",
      "   [ 0.85478723]\n",
      "   [-2.4673572 ]\n",
      "   [ 1.1871167 ]\n",
      "   [ 1.1666896 ]]\n",
      "\n",
      "  [[ 1.2930567 ]\n",
      "   [-0.5701357 ]\n",
      "   [-2.2703435 ]\n",
      "   [-1.9223319 ]\n",
      "   [ 0.27040118]\n",
      "   [ 0.30775297]\n",
      "   [ 1.4853232 ]\n",
      "   [ 0.913123  ]\n",
      "   [-1.441019  ]\n",
      "   [-1.8959848 ]]\n",
      "\n",
      "  [[ 1.0159587 ]\n",
      "   [ 0.0694961 ]\n",
      "   [-1.9741024 ]\n",
      "   [-0.8571747 ]\n",
      "   [ 0.97208077]\n",
      "   [-0.04656637]\n",
      "   [-0.17147818]\n",
      "   [-0.38195935]\n",
      "   [ 0.7150294 ]\n",
      "   [-0.6185271 ]]\n",
      "\n",
      "  [[ 0.7394768 ]\n",
      "   [-0.71651644]\n",
      "   [ 1.0766954 ]\n",
      "   [ 1.3313543 ]\n",
      "   [-1.1710277 ]\n",
      "   [-1.4651469 ]\n",
      "   [-1.0059258 ]\n",
      "   [-0.3706056 ]\n",
      "   [-0.13829523]\n",
      "   [-0.08565768]]\n",
      "\n",
      "  [[-0.49593356]\n",
      "   [-1.6987771 ]\n",
      "   [ 0.9432426 ]\n",
      "   [ 0.24689567]\n",
      "   [-1.4053421 ]\n",
      "   [-0.3704833 ]\n",
      "   [-0.22527519]\n",
      "   [ 1.8346455 ]\n",
      "   [-1.6561409 ]\n",
      "   [ 1.1406704 ]]\n",
      "\n",
      "  [[-1.1876777 ]\n",
      "   [-0.5840105 ]\n",
      "   [-0.69022506]\n",
      "   [-1.3481454 ]\n",
      "   [-0.6893132 ]\n",
      "   [ 0.6955745 ]\n",
      "   [ 0.4869986 ]\n",
      "   [ 0.82967925]\n",
      "   [ 0.25656703]\n",
      "   [ 0.780585  ]]\n",
      "\n",
      "  [[ 0.277036  ]\n",
      "   [-1.967071  ]\n",
      "   [-0.9883843 ]\n",
      "   [ 0.6123662 ]\n",
      "   [ 0.43740985]\n",
      "   [ 0.39252585]\n",
      "   [ 0.05333892]\n",
      "   [ 1.4735454 ]\n",
      "   [-0.57740504]\n",
      "   [-1.4391862 ]]\n",
      "\n",
      "  [[-0.88972646]\n",
      "   [-2.3388553 ]\n",
      "   [ 0.35594544]\n",
      "   [ 1.6600848 ]\n",
      "   [-0.6279919 ]\n",
      "   [ 0.3807918 ]\n",
      "   [-1.4523549 ]\n",
      "   [-0.06087148]\n",
      "   [-0.50910616]\n",
      "   [-0.36625898]]]] \n",
      "\n",
      "Filter/Kernel \n",
      "\n",
      "[[[[ 1.5027119 ]]\n",
      "\n",
      "  [[ 1.0511703 ]]\n",
      "\n",
      "  [[-0.35945943]]]\n",
      "\n",
      "\n",
      " [[[-1.1492758 ]]\n",
      "\n",
      "  [[ 1.0860231 ]]\n",
      "\n",
      "  [[ 0.11458056]]]\n",
      "\n",
      "\n",
      " [[[-1.393188  ]]\n",
      "\n",
      "  [[ 1.4925256 ]]\n",
      "\n",
      "  [[-0.85834605]]]] \n",
      "\n",
      "Result/Feature Map with valid positions \n",
      "\n",
      "[[[[ 1.3806195 ]\n",
      "   [ 1.5661094 ]\n",
      "   [ 1.6892929 ]\n",
      "   [-0.35513517]\n",
      "   [-1.2989229 ]\n",
      "   [ 2.7829134 ]\n",
      "   [-8.265031  ]\n",
      "   [ 3.4929175 ]]\n",
      "\n",
      "  [[ 1.1345161 ]\n",
      "   [ 0.36317414]\n",
      "   [-0.78156835]\n",
      "   [ 5.974552  ]\n",
      "   [ 0.22905006]\n",
      "   [ 2.602469  ]\n",
      "   [-2.7815921 ]\n",
      "   [ 0.95663   ]]\n",
      "\n",
      "  [[-3.316798  ]\n",
      "   [-5.963157  ]\n",
      "   [ 1.0691584 ]\n",
      "   [ 5.2279315 ]\n",
      "   [-1.0402594 ]\n",
      "   [ 3.2970662 ]\n",
      "   [-3.5612457 ]\n",
      "   [-3.5806448 ]]\n",
      "\n",
      "  [[-2.1822844 ]\n",
      "   [-3.411799  ]\n",
      "   [-2.5881226 ]\n",
      "   [-3.0246136 ]\n",
      "   [-0.68336177]\n",
      "   [ 2.3770473 ]\n",
      "   [ 4.5410466 ]\n",
      "   [ 2.0670156 ]]\n",
      "\n",
      "  [[-1.849461  ]\n",
      "   [ 4.0453806 ]\n",
      "   [-3.882029  ]\n",
      "   [-5.342737  ]\n",
      "   [ 2.7111526 ]\n",
      "   [-0.9588314 ]\n",
      "   [ 4.2951913 ]\n",
      "   [-5.3410287 ]]\n",
      "\n",
      "  [[ 0.17960182]\n",
      "   [ 3.5221741 ]\n",
      "   [ 2.0025845 ]\n",
      "   [-0.30372345]\n",
      "   [-0.17079428]\n",
      "   [-3.6888876 ]\n",
      "   [ 0.5497482 ]\n",
      "   [-5.8908954 ]]\n",
      "\n",
      "  [[-4.6918645 ]\n",
      "   [-1.1432065 ]\n",
      "   [ 3.3478034 ]\n",
      "   [-0.62980586]\n",
      "   [-0.88618916]\n",
      "   [-3.3605278 ]\n",
      "   [ 5.176676  ]\n",
      "   [-1.6588178 ]]\n",
      "\n",
      "  [[-7.2752185 ]\n",
      "   [ 2.5037198 ]\n",
      "   [ 2.1653836 ]\n",
      "   [-6.761211  ]\n",
      "   [ 2.1398466 ]\n",
      "   [-1.6113654 ]\n",
      "   [ 5.3541117 ]\n",
      "   [-1.610284  ]]]]\n",
      "\n",
      "\n",
      "Result/Feature Map with padding \n",
      "\n",
      "[[[[ 3.5231462 ]\n",
      "   [-1.4769872 ]\n",
      "   [-3.8087997 ]\n",
      "   [ 0.86706966]\n",
      "   [ 0.958365  ]\n",
      "   [-2.0315313 ]\n",
      "   [ 0.08736727]\n",
      "   [-0.39864337]\n",
      "   [-0.47154322]\n",
      "   [ 3.809082  ]]\n",
      "\n",
      "  [[ 4.4596353 ]\n",
      "   [ 1.3806195 ]\n",
      "   [ 1.5661094 ]\n",
      "   [ 1.6892929 ]\n",
      "   [-0.35513517]\n",
      "   [-1.2989229 ]\n",
      "   [ 2.7829134 ]\n",
      "   [-8.265031  ]\n",
      "   [ 3.4929175 ]\n",
      "   [ 2.4288578 ]]\n",
      "\n",
      "  [[ 3.2043836 ]\n",
      "   [ 1.1345161 ]\n",
      "   [ 0.36317414]\n",
      "   [-0.78156835]\n",
      "   [ 5.974552  ]\n",
      "   [ 0.22905006]\n",
      "   [ 2.602469  ]\n",
      "   [-2.7815921 ]\n",
      "   [ 0.95663   ]\n",
      "   [-0.706789  ]]\n",
      "\n",
      "  [[ 3.1709654 ]\n",
      "   [-3.316798  ]\n",
      "   [-5.963157  ]\n",
      "   [ 1.0691584 ]\n",
      "   [ 5.2279315 ]\n",
      "   [-1.0402594 ]\n",
      "   [ 3.2970662 ]\n",
      "   [-3.5612457 ]\n",
      "   [-3.5806448 ]\n",
      "   [ 0.687991  ]]\n",
      "\n",
      "  [[ 4.394188  ]\n",
      "   [-2.1822844 ]\n",
      "   [-3.411799  ]\n",
      "   [-2.5881226 ]\n",
      "   [-3.0246136 ]\n",
      "   [-0.68336177]\n",
      "   [ 2.3770473 ]\n",
      "   [ 4.5410466 ]\n",
      "   [ 2.0670156 ]\n",
      "   [-5.5871153 ]]\n",
      "\n",
      "  [[ 2.4818997 ]\n",
      "   [-1.849461  ]\n",
      "   [ 4.0453806 ]\n",
      "   [-3.882029  ]\n",
      "   [-5.342737  ]\n",
      "   [ 2.7111526 ]\n",
      "   [-0.9588314 ]\n",
      "   [ 4.2951913 ]\n",
      "   [-5.3410287 ]\n",
      "   [ 4.5000143 ]]\n",
      "\n",
      "  [[-0.96972376]\n",
      "   [ 0.17960182]\n",
      "   [ 3.5221741 ]\n",
      "   [ 2.0025845 ]\n",
      "   [-0.30372345]\n",
      "   [-0.17079428]\n",
      "   [-3.6888876 ]\n",
      "   [ 0.5497482 ]\n",
      "   [-5.8908954 ]\n",
      "   [ 3.6518953 ]]\n",
      "\n",
      "  [[ 0.8344801 ]\n",
      "   [-4.6918645 ]\n",
      "   [-1.1432065 ]\n",
      "   [ 3.3478034 ]\n",
      "   [-0.62980586]\n",
      "   [-0.88618916]\n",
      "   [-3.3605278 ]\n",
      "   [ 5.176676  ]\n",
      "   [-1.6588178 ]\n",
      "   [-2.0803852 ]]\n",
      "\n",
      "  [[-0.2834365 ]\n",
      "   [-7.2752185 ]\n",
      "   [ 2.5037198 ]\n",
      "   [ 2.1653836 ]\n",
      "   [-6.761211  ]\n",
      "   [ 2.1398466 ]\n",
      "   [-1.6113654 ]\n",
      "   [ 5.3541117 ]\n",
      "   [-1.610284  ]\n",
      "   [ 0.46931192]]\n",
      "\n",
      "  [[-0.23595656]\n",
      "   [-2.772863  ]\n",
      "   [-0.95025396]\n",
      "   [ 0.32306853]\n",
      "   [-1.3073727 ]\n",
      "   [ 2.0196123 ]\n",
      "   [-1.9056587 ]\n",
      "   [ 3.3813689 ]\n",
      "   [ 1.5997831 ]\n",
      "   [-2.1931658 ]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "#Building graph\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    input = tf.Variable(tf.random_normal([1, 10, 10, 1]))\n",
    "    filter = tf.Variable(tf.random_normal([3, 3, 1, 1]))\n",
    "    op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    op2 = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    #Initialization and session\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "# Running graph in session\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    print(\"Input \\n\")\n",
    "    print('{0} \\n'.format(input.eval()))\n",
    "    print(\"Filter/Kernel \\n\")\n",
    "    print('{0} \\n'.format(filter.eval()))\n",
    "    print(\"Result/Feature Map with valid positions \\n\")\n",
    "    result = sess.run(op)\n",
    "    print(result)\n",
    "    print('\\n')\n",
    "    print(\"Result/Feature Map with padding \\n\")\n",
    "    result2 = sess.run(op2)\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref4\"></a>\n",
    "<h2>Convolution applied on images</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload your own image (drag and drop to this window) and type its name on the input field on the next cell (press <b>shift + enter</b>). The result of this pre-processing will be an image with only a grayscale channel.\n",
    "\n",
    "You can type <b>bird.jpg</b> to use a default image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original type: <PIL.Image.Image image mode=L size=640x1136 at 0x132084E48> \n",
      "\n",
      "\n",
      "After conversion to numerical representation: \n",
      "\n",
      " array([[24, 24, 24, ..., 24, 24, 24],\n",
      "       [24, 24, 24, ..., 24, 24, 24],\n",
      "       [24, 24, 24, ..., 24, 24, 24],\n",
      "       ...,\n",
      "       [34, 34, 34, ..., 34, 34, 34],\n",
      "       [34, 34, 34, ..., 34, 34, 34],\n",
      "       [34, 34, 34, ..., 34, 34, 34]], dtype=uint8)\n",
      "\n",
      " Input image converted to gray scale: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Importing\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('test_image.png')  # type here your image's name\n",
    "\n",
    "image_gr = im.convert(\"L\")    # convert(\"L\") translate color images into black and white\n",
    "                              # uses the ITU-R 601-2 Luma transform (there are several \n",
    "                              # ways to convert an image to grey scale)\n",
    "print(\"\\n Original type: %r \\n\\n\" % image_gr)\n",
    "\n",
    "# convert image to a matrix with values from 0 to 255 (uint8) \n",
    "arr = np.asarray(image_gr) \n",
    "print(\"After conversion to numerical representation: \\n\\n %r\" % arr) \n",
    "### Activating matplotlib for Ipython\n",
    "%matplotlib inline\n",
    "\n",
    "### Plot image\n",
    "\n",
    "imgplot = plt.imshow(arr)\n",
    "imgplot.set_cmap('gray')  #you can experiment different colormaps (Greys,winter,autumn)\n",
    "print(\"\\n Input image converted to gray scale: \\n\")\n",
    "plt.show(imgplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will experiment using an edge detector kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = np.array([[ 0, 1, 0],\n",
    "                   [ 1,-4, 1],\n",
    "                   [ 0, 1, 0],]) \n",
    "\n",
    "grad = signal.convolve2d(arr, kernel, mode='same', boundary='symm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print('GRADIENT MAGNITUDE - Feature map')\n",
    "\n",
    "fig, aux = plt.subplots(figsize=(10, 10))\n",
    "aux.imshow(np.absolute(grad), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the kernel and start to analyze the outputs we would be acting as a CNN. The difference is that a Neural Network do all this work automatically (the kernel adjustment using different weights). In addition, we can understand how biases affect the behaviour of feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Please note that when you are dealing with most of the real applications of CNNs, you usually convert the pixels values to a range from 0 to 1. This process is called normalization.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(grad)\n",
    "\n",
    "grad_biases = np.absolute(grad) + 100\n",
    "\n",
    "grad_biases[grad_biases > 255] = 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print('GRADIENT MAGNITUDE - Feature map')\n",
    "\n",
    "fig, aux = plt.subplots(figsize=(10, 10))\n",
    "aux.imshow(np.absolute(grad_biases), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how it works for a digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download standard image\n",
    "!wget --quiet https://ibm.box.com/shared/static/vvm1b63uvuxq88vbw9znpwu5ol380mco.jpg --output-document num3.jpg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Importing\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('num3.jpg')  # type here your image's name\n",
    "\n",
    "image_gr = im.convert(\"L\")    # convert(\"L\") translate color images into black and white\n",
    "                              # uses the ITU-R 601-2 Luma transform (there are several \n",
    "                              # ways to convert an image to grey scale)\n",
    "print(\"\\n Original type: %r \\n\\n\" % image_gr)\n",
    "\n",
    "# convert image to a matrix with values from 0 to 255 (uint8) \n",
    "arr = np.asarray(image_gr) \n",
    "print(\"After conversion to numerical representation: \\n\\n %r\" % arr) \n",
    "### Activating matplotlib for Ipython\n",
    "%matplotlib inline\n",
    "\n",
    "### Plot image\n",
    "fig, aux = plt.subplots(figsize=(10, 10))\n",
    "imgplot = plt.imshow(arr)\n",
    "imgplot.set_cmap('gray')  #you can experiment different colormaps (Greys,winter,autumn)\n",
    "print(\"\\n Input image converted to gray scale: \\n\")\n",
    "plt.show(imgplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will experiment using an edge detector kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = np.array([\n",
    "                        [ 0, 1, 0],\n",
    "                        [ 1,-4, 1],\n",
    "                        [ 0, 1, 0],\n",
    "                                     ]) \n",
    "\n",
    "grad = signal.convolve2d(arr, kernel, mode='same', boundary='symm')\n",
    "%matplotlib inline\n",
    "\n",
    "print('GRADIENT MAGNITUDE - Feature map')\n",
    "\n",
    "fig, aux = plt.subplots(figsize=(10, 10))\n",
    "aux.imshow(np.absolute(grad), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref5\"></a>\n",
    "<h2>Conclusion</h2>\n",
    "\n",
    "This understanding of how convolutions work are the foundation of how Convolutional Neural Networks work. After this tutorial you are supposed to understand the underlying mathematical concepts and how to apply them using| Python (Numpy) and TensorFlow. The next step is to extrapolate this knowledge to Machine Learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "Running deep learning programs usually needs a high performance platform. __PowerAI__ speeds up deep learning and AI. Built on IBMâ€™s Power Systems, __PowerAI__ is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The __PowerAI__ platform supports popular machine learning libraries and dependencies including TensorFlow, Caffe, Torch, and Theano. You can use [PowerAI on IMB Cloud](https://cocl.us/ML0120EN_PAI).\n",
    "\n",
    "Also, you can use __Watson Studio__ to run these notebooks faster with bigger datasets.__Watson Studio__ is IBMâ€™s leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, __Watson Studio__ enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of __Watson Studio__ users today with a free account at [Watson Studio](https://cocl.us/ML0120EN_DSX).This is the end of this lesson. Thank you for reading this notebook, and good luck on your studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks for completing this lesson!\n",
    "\n",
    "If you are familiar with some of these methods and concepts, this tutorial might have been boring for you, but it is important to get used to the TensorFlow mechanics, and feel familiar and comfortable using it, so you can build more complex algorithms in it.\n",
    "\n",
    "Created by <a href=\"https://linkedin.com/in/saeedaghabozorgi\"> Saeed Aghabozorgi </a> , <a href=\"https://ca.linkedin.com/in/rafaelblsilva\"> Rafael Belo Da Silva</a><br />\n",
    "\n",
    "This tutorial was inspired by the documentation of TensorFlow : https://www.tensorflow.org/versions/r0.9/get_started/index.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/joanbruna/stat212b/blob/master/lec1.pdf  \n",
    "http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution  \n",
    "http://homepages.inf.ed.ac.uk/rbf/HIPR2/fourier.htm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
